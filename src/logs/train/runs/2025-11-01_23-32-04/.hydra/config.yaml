task_name: train
tags:
- dev
train: true
test: true
ckpt_path: null
seed: 24
data:
  _target_: data.crypto_datamodule.CryptoDataModule
  data_dir: ${paths.data_dir}/crypto-700
  end_date: '2025-09-29'
  validation_start_date: '2025-06-01'
  barrier_up: 0.02
  barrier_down: 0.02
  barrier_horizon: 4
  lookback_window: 64
  candle_length: 60000
  portfolio_size: 10
  max_coins: 10
  batch_size: 2
  num_workers: 4
model:
  _target_: models.trader_module.TraderLitModule
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 0.0
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10
  net:
    _target_: models.components.simple_dense_net.SimpleDenseNet
    input_size: 784
    lin1_size: 64
    lin2_size: 128
    lin3_size: 64
    output_size: 10
  compile: false
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: val/acc
    verbose: false
    save_last: true
    save_top_k: 1
    mode: max
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val/acc
    min_delta: 0.0
    patience: 100
    verbose: false
    mode: max
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: -1
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
    theme:
      _target_: lightning.pytorch.callbacks.progress.rich_progress.RichProgressBarTheme
      metrics: '#f39c12'
      time: '#e67e22'
      metrics_text_delimiter: '

        | '
      description: '#e67e22'
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1
  max_epochs: 10
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 1
  deterministic: false
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config: true
